UCS 645: Parallel & Distributed Computing - Lab Exercise #5
Learning Outcomes

• How to query CUDA device properties.
• Understanding how to observe the difference between theoretical and measured memory bandwidth.

Problem 1

Write a CUDA program for a very basic implementation of a vector addition kernel. Compute the profiling of the object using `nvprof`. Complete the following changes:


1.1 Modify the example to use statically defined global variables (i.e. where the size is declared at compile time and you do not need to use `cudaMalloc`). 
Note: A device symbol (statically defined CUDA memory) is not the same as a device address in the host code. Passing a symbol as an argument to the kernel launch will cause invalid memory accesses in the kernel.


1.2 Modify the code to record timing data of the kernel execution. Print this data to the console.


1.3 We would like to query the device properties so that we can calculate the theoretical memory bandwidth of the device.
The formula for theoretical bandwidth is given by:

    theoreticalBW = memoryClockRate * memoryBusWidth * 2

Using `cudaDeviceProp`, query the two values from the first CUDA device available and multiply these by 2 (as DDR memory is double pumped). 
Convert the result to GB/s and print it to the console. (memoryClockRate is in kHz and memoryBusWidth is in bits).


1.4 Theoretical bandwidth is the maximum bandwidth we could achieve in ideal conditions. We will calculate the measured bandwidth of the `vectorAdd` kernel.

    measuredBW = (RBytes + WBytes) / t

Where RBytes is the number of bytes read and WBytes is the number of bytes written by the kernel. You can calculate these values by considering how many bytes the kernel reads and writes and multiplying it by the number of threads launched.
`t` is the time (in seconds) recorded from your timing data. Print the measured bandwidth to the console so that you can compare it with the theoretical bandwidth.
Note: Switch to Release mode to profile your code execution times.

CUDA Code for Vector Addition with Profiling and Bandwidth Measurement

#include <iostream>
#include <cuda_runtime.h>
#include <device_launch_parameters.h>
#include <chrono>

#define N 1024
__device__ int A[N], B[N], C[N];  // statically allocated device memory

__global__ void vectorAdd() {
    int i = threadIdx.x + blockIdx.x * blockDim.x;
    if (i < N) {
        C[i] = A[i] + B[i];
    }
}

int main() {
    int h_A[N], h_B[N], h_C[N];

    // Initialize input vectors
    for (int i = 0; i < N; ++i) {
        h_A[i] = i;
        h_B[i] = i * 2;
    }

    // Copy data to statically allocated device memory
    cudaMemcpyToSymbol(A, h_A, sizeof(int) * N);
    cudaMemcpyToSymbol(B, h_B, sizeof(int) * N);

    // Record the start time
    cudaEvent_t start, stop;
    cudaEventCreate(&start);
    cudaEventCreate(&stop);
    cudaEventRecord(start);

    // Launch kernel
    vectorAdd<<<(N + 255) / 256, 256>>>();

    // Record the end time
    cudaEventRecord(stop);
    cudaEventSynchronize(stop);
    float milliseconds = 0;
    cudaEventElapsedTime(&milliseconds, start, stop);

    // Copy result back to host
    cudaMemcpyFromSymbol(h_C, C, sizeof(int) * N);

    // Print timing
    std::cout << "Kernel execution time: " << milliseconds << " ms\n";

    // Query device properties
    cudaDeviceProp prop;
    cudaGetDeviceProperties(&prop, 0);

    float memoryClockRate = prop.memoryClockRate; // in kHz
    float memoryBusWidth = prop.memoryBusWidth;   // in bits

    float theoreticalBW = 2.0f * memoryClockRate * memoryBusWidth / 8.0f / 1e6f; // in GB/s
    std::cout << "Theoretical Bandwidth: " << theoreticalBW << " GB/s\n";

    // Measured Bandwidth calculation
    float RBytes = 2 * N * sizeof(int);  // A and B
    float WBytes = N * sizeof(int);      // C
    float seconds = milliseconds / 1000.0f;
    float measuredBW = (RBytes + WBytes) / (seconds * 1e9);
    std::cout << "Measured Bandwidth: " << measuredBW << " GB/s\n";

    return 0;
}
